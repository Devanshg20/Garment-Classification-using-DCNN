{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14479,"status":"ok","timestamp":1656786406751,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"0NyD-6P17yJj","outputId":"bdc0cb1e-d0af-435c-e51e-b44496080f89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":[" from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656787110805,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"YTyIfboO7Y0L"},"outputs":[],"source":[" import os, shutil\n","import numpy as np\n","\n","from matplotlib import image, pyplot\n","from skimage.transform import resize\n","\n","\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential, Model\n","from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n","\n","from keras import callbacks\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, f1_score, recall_score,classification_report,roc_curve, auc \n","from sklearn.svm import SVC\n","from sklearn import svm"]},{"cell_type":"markdown","source":["**For western/ ethenic classification**"],"metadata":{"id":"BrUHYZq3QrMk"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gg4ttjJl8Ez4","executionInfo":{"status":"ok","timestamp":1656787109268,"user_tz":-330,"elapsed":238798,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}},"outputId":"df7fd4e6-9991-4c72-abd6-4aa4a03f026b"},"outputs":[{"output_type":"stream","name":"stdout","text":[">>>Reading  western\n","1\n",">>>Reading  ethenic\n","0\n"]}],"source":["DATA_PATH = '/content/drive/MyDrive/updatedDataset/'\n","westEth=[]\n","labelwe=[]\n","hashList=[]\n","count=2\n","for folder in os.listdir(DATA_PATH):\n","    if folder==\"Gender\":\n","      continue;\n","    print(\">>>Reading \",folder)\n","    count-=1\n","    print(count)\n","    \n","    for file in os.listdir(DATA_PATH+folder):\n","         if(str(file).endswith('.jpg') or str(file).endswith('.JPG') or str(file).endswith('.jpeg') or str(file).endswith('.JPEG')):\n","            img = image.imread(DATA_PATH+folder+'/'+file)\n","            hsh = hash(tuple(np.array(img).flatten()))\n","            if(hsh not in hashList):\n","              westEth.append(resize(img, (156, 156, 3)))\n","              hashList.append(hsh)\n","              labelwe.append(count)\n","westEth=np.array(westEth)\n","labelwe=np.array(labelwe)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":424,"status":"ok","timestamp":1656787238905,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"BtQFqoDl-NB3"},"outputs":[],"source":["resultPath = '/content/drive/MyDrive/Resultse'\n","train_folder = os.listdir(DATA_PATH).remove(\"Gender\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":706,"status":"ok","timestamp":1656787240136,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"6iymjlx0-gxE","outputId":"1491c280-5893-4a69-e0b0-80fbcd67485a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Ethenic 1715\n","Number of western 1873\n"]}],"source":["print(\"Number of Ethenic\",len(labelwe[labelwe==0]))\n","print(\"Number of western\",len(labelwe[labelwe==1]))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656787241904,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"OxqY62v0-zx2","outputId":"6e53dd03-fc89-4636-e26e-8461a6ede6ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["western/ethenic data shape :  (3588, 156, 156, 3)  Label shape :  (3588,)\n"]}],"source":["print(\"western/ethenic data shape : \",westEth.shape,\" Label shape : \",labelwe.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1730,"status":"ok","timestamp":1656787244426,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"pOe6-K3Q_bFC"},"outputs":[],"source":["testPercentage=0.3\n","x_train,x_test,y_train,y_test = train_test_split(westEth,labelwe,test_size = testPercentage,random_state=50, stratify=labelwe,shuffle=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656787244427,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"5esxXepI_hq6","outputId":"825d56cc-463d-45eb-f4a1-69cfa68a9c46"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape :  (2511, 156, 156, 3)  y_train shape :  (2511,)\n","x_test shape :  (1077, 156, 156, 3)  y_test shape :  (1077,)\n"]}],"source":["print(\"x_train shape : \",x_train.shape,\" y_train shape : \",y_train.shape)\n","print(\"x_test shape : \",x_test.shape,\" y_test shape : \",y_test.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656787245130,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"EF-3JnQs_lnK","outputId":"b49196e4-e95d-4406-b43f-e32c42b33c5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of train ethenic 1200\n","Number of train western 1311\n","Number of test  ethenic 515\n","Number of test western 562\n"]}],"source":["print(\"Number of train ethenic\",len(y_train[y_train==0]))\n","print(\"Number of train western\",len(y_train[y_train==1]))\n","\n","print(\"Number of test  ethenic\",len(y_test[y_test==0]))\n","print(\"Number of test western\",len(y_test[y_test==1]))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1048,"status":"ok","timestamp":1656787247794,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"8jleh1hF0w9y","outputId":"3368d2af-4752-45fe-8283-3f5eea6bda86"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 156, 156, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 78, 78, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 78, 78, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 39, 39, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 39, 39, 128)       73856     \n","                                                                 \n"," dropout (Dropout)           (None, 39, 39, 128)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 194688)            0         \n","                                                                 \n"," dense (Dense)               (None, 128)               24920192  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 25,013,569\n","Trainable params: 25,013,569\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["NO_OF_EPOCHS=100\n","BATCH_SIZE=32\n","\n","model2=Sequential()\n","model2.add(Conv2D(32,kernel_size=3, padding='same',activation='relu',input_shape=(156, 156,3)))\n","model2.add(MaxPool2D(pool_size=(2, 2)))\n","model2.add(Conv2D(64,kernel_size=3, padding='same',activation='relu'))\n","model2.add(MaxPool2D(pool_size=(2, 2)))\n","model2.add(Conv2D(128,kernel_size=3, padding='same',activation='relu'))\n","model2.add(Dropout(0.1))\n","model2.add(Flatten())\n","model2.add(Dense(128,activation='relu'))\n","model2.add(Dropout(0.1))\n","model2.add(Dense(1,activation='sigmoid'))\n","model2.summary()\n","model2.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14725644,"status":"ok","timestamp":1656723914927,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"lITTnPm8AGQu","outputId":"407192a0-4c18-499d-e30f-80c2c6e36c23"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","79/79 [==============================] - ETA: 0s - loss: 0.9055 - accuracy: 0.5337\n","Epoch 1: val_accuracy improved from -inf to 0.52089, saving model to /content/drive/MyDrive/Resultse/checkpoint-0001.hdf5\n","79/79 [==============================] - 158s 2s/step - loss: 0.9055 - accuracy: 0.5337 - val_loss: 0.7024 - val_accuracy: 0.5209 - lr: 0.0010\n","Epoch 2/100\n","79/79 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.5508\n","Epoch 2: val_accuracy improved from 0.52089 to 0.52182, saving model to /content/drive/MyDrive/Resultse/checkpoint-0002.hdf5\n","79/79 [==============================] - 150s 2s/step - loss: 0.6856 - accuracy: 0.5508 - val_loss: 0.7683 - val_accuracy: 0.5218 - lr: 0.0010\n","Epoch 3/100\n","79/79 [==============================] - ETA: 0s - loss: 0.6671 - accuracy: 0.5890\n","Epoch 3: val_accuracy improved from 0.52182 to 0.58960, saving model to /content/drive/MyDrive/Resultse/checkpoint-0003.hdf5\n","79/79 [==============================] - 152s 2s/step - loss: 0.6671 - accuracy: 0.5890 - val_loss: 0.6860 - val_accuracy: 0.5896 - lr: 0.0010\n","Epoch 4/100\n","79/79 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.6738\n","Epoch 4: val_accuracy did not improve from 0.58960\n","79/79 [==============================] - 149s 2s/step - loss: 0.6022 - accuracy: 0.6738 - val_loss: 0.7731 - val_accuracy: 0.5655 - lr: 0.0010\n","Epoch 5/100\n","79/79 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.7463\n","Epoch 5: val_accuracy improved from 0.58960 to 0.59517, saving model to /content/drive/MyDrive/Resultse/checkpoint-0005.hdf5\n","79/79 [==============================] - 152s 2s/step - loss: 0.4944 - accuracy: 0.7463 - val_loss: 0.7787 - val_accuracy: 0.5952 - lr: 0.0010\n","Epoch 6/100\n","79/79 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8319\n","Epoch 6: val_accuracy improved from 0.59517 to 0.61096, saving model to /content/drive/MyDrive/Resultse/checkpoint-0006.hdf5\n","79/79 [==============================] - 151s 2s/step - loss: 0.3462 - accuracy: 0.8319 - val_loss: 1.0280 - val_accuracy: 0.6110 - lr: 0.0010\n","Epoch 7/100\n","79/79 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.8980\n","Epoch 7: val_accuracy did not improve from 0.61096\n","79/79 [==============================] - 150s 2s/step - loss: 0.2413 - accuracy: 0.8980 - val_loss: 1.1018 - val_accuracy: 0.6063 - lr: 0.0010\n","Epoch 8/100\n","79/79 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9311\n","Epoch 8: val_accuracy improved from 0.61096 to 0.61746, saving model to /content/drive/MyDrive/Resultse/checkpoint-0008.hdf5\n","79/79 [==============================] - 150s 2s/step - loss: 0.1572 - accuracy: 0.9311 - val_loss: 1.6032 - val_accuracy: 0.6175 - lr: 0.0010\n","Epoch 9/100\n","79/79 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9506\n","Epoch 9: val_accuracy improved from 0.61746 to 0.62581, saving model to /content/drive/MyDrive/Resultse/checkpoint-0009.hdf5\n","79/79 [==============================] - 149s 2s/step - loss: 0.1112 - accuracy: 0.9506 - val_loss: 1.8486 - val_accuracy: 0.6258 - lr: 0.0010\n","Epoch 10/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9646\n","Epoch 10: val_accuracy did not improve from 0.62581\n","79/79 [==============================] - 150s 2s/step - loss: 0.0864 - accuracy: 0.9646 - val_loss: 2.2780 - val_accuracy: 0.6165 - lr: 0.0010\n","Epoch 11/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9769\n","Epoch 11: val_accuracy improved from 0.62581 to 0.63788, saving model to /content/drive/MyDrive/Resultse/checkpoint-0011.hdf5\n","79/79 [==============================] - 149s 2s/step - loss: 0.0658 - accuracy: 0.9769 - val_loss: 2.2990 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 12/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9825\n","Epoch 12: val_accuracy improved from 0.63788 to 0.64345, saving model to /content/drive/MyDrive/Resultse/checkpoint-0012.hdf5\n","79/79 [==============================] - 150s 2s/step - loss: 0.0458 - accuracy: 0.9825 - val_loss: 2.6178 - val_accuracy: 0.6435 - lr: 0.0010\n","Epoch 13/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9932\n","Epoch 13: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 150s 2s/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 3.0574 - val_accuracy: 0.6305 - lr: 0.0010\n","Epoch 14/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9896\n","Epoch 14: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 2.6836 - val_accuracy: 0.6156 - lr: 0.0010\n","Epoch 15/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9912\n","Epoch 15: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 149s 2s/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 2.9224 - val_accuracy: 0.6360 - lr: 0.0010\n","Epoch 16/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9968\n","Epoch 16: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 149s 2s/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 2.8976 - val_accuracy: 0.6277 - lr: 0.0010\n","Epoch 17/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9948\n","Epoch 17: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 149s 2s/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 3.2571 - val_accuracy: 0.6305 - lr: 0.0010\n","Epoch 18/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9948\n","Epoch 18: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 149s 2s/step - loss: 0.0311 - accuracy: 0.9948 - val_loss: 3.6437 - val_accuracy: 0.6416 - lr: 0.0010\n","Epoch 19/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9904\n","Epoch 19: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0313 - accuracy: 0.9904 - val_loss: 3.2789 - val_accuracy: 0.6305 - lr: 0.0010\n","Epoch 20/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9920\n","Epoch 20: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0219 - accuracy: 0.9920 - val_loss: 3.3773 - val_accuracy: 0.6425 - lr: 0.0010\n","Epoch 21/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9944\n","Epoch 21: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 149s 2s/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 3.3976 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 22/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9980\n","Epoch 22: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 149s 2s/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 3.7708 - val_accuracy: 0.6407 - lr: 0.0010\n","Epoch 23/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9980\n","Epoch 23: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 146s 2s/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 3.9247 - val_accuracy: 0.6388 - lr: 0.0010\n","Epoch 24/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9968\n","Epoch 24: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 146s 2s/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 4.1554 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 25/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9976\n","Epoch 25: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 4.1700 - val_accuracy: 0.6360 - lr: 0.0010\n","Epoch 26/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9984\n","Epoch 26: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 150s 2s/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 4.0685 - val_accuracy: 0.6323 - lr: 0.0010\n","Epoch 27/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9964\n","Epoch 27: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 149s 2s/step - loss: 0.0210 - accuracy: 0.9964 - val_loss: 3.2592 - val_accuracy: 0.6305 - lr: 0.0010\n","Epoch 28/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9936\n","Epoch 28: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 149s 2s/step - loss: 0.0315 - accuracy: 0.9936 - val_loss: 3.3615 - val_accuracy: 0.6305 - lr: 0.0010\n","Epoch 29/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9881\n","Epoch 29: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0438 - accuracy: 0.9881 - val_loss: 2.9561 - val_accuracy: 0.6240 - lr: 0.0010\n","Epoch 30/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9924\n","Epoch 30: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0285 - accuracy: 0.9924 - val_loss: 3.6145 - val_accuracy: 0.6147 - lr: 0.0010\n","Epoch 31/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9948\n","Epoch 31: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0130 - accuracy: 0.9948 - val_loss: 3.7575 - val_accuracy: 0.6249 - lr: 0.0010\n","Epoch 32/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9980\n","Epoch 32: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 4.0401 - val_accuracy: 0.6156 - lr: 0.0010\n","Epoch 33/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9992\n","Epoch 33: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 4.4373 - val_accuracy: 0.6091 - lr: 0.0010\n","Epoch 34/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9984\n","Epoch 34: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 4.3870 - val_accuracy: 0.6110 - lr: 0.0010\n","Epoch 35/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n","Epoch 35: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 4.4996 - val_accuracy: 0.6147 - lr: 0.0010\n","Epoch 36/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9976\n","Epoch 36: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 4.8564 - val_accuracy: 0.6119 - lr: 0.0010\n","Epoch 37/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9936\n","Epoch 37: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 146s 2s/step - loss: 0.0160 - accuracy: 0.9936 - val_loss: 4.7744 - val_accuracy: 0.6230 - lr: 0.0010\n","Epoch 38/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9956\n","Epoch 38: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0099 - accuracy: 0.9956 - val_loss: 4.5996 - val_accuracy: 0.6184 - lr: 0.0010\n","Epoch 39/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9952\n","Epoch 39: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0124 - accuracy: 0.9952 - val_loss: 4.4758 - val_accuracy: 0.6221 - lr: 0.0010\n","Epoch 40/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9976\n","Epoch 40: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 4.6639 - val_accuracy: 0.6240 - lr: 0.0010\n","Epoch 41/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9940\n","Epoch 41: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0242 - accuracy: 0.9940 - val_loss: 4.3537 - val_accuracy: 0.6267 - lr: 0.0010\n","Epoch 42/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9956\n","Epoch 42: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 3.3602 - val_accuracy: 0.6295 - lr: 0.0010\n","Epoch 43/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9980\n","Epoch 43: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 4.0151 - val_accuracy: 0.6267 - lr: 0.0010\n","Epoch 44/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968\n","Epoch 44: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 4.2208 - val_accuracy: 0.6249 - lr: 0.0010\n","Epoch 45/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n","Epoch 45: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 4.5014 - val_accuracy: 0.6128 - lr: 0.0010\n","Epoch 46/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9992\n","Epoch 46: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 4.6881 - val_accuracy: 0.6249 - lr: 0.0010\n","Epoch 47/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9988\n","Epoch 47: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 4.6008 - val_accuracy: 0.6295 - lr: 0.0010\n","Epoch 48/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9984\n","Epoch 48: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 4.3729 - val_accuracy: 0.6295 - lr: 0.0010\n","Epoch 49/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n","Epoch 49: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 146s 2s/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 4.5243 - val_accuracy: 0.6258 - lr: 0.0010\n","Epoch 50/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9980\n","Epoch 50: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 150s 2s/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 4.8582 - val_accuracy: 0.6277 - lr: 0.0010\n","Epoch 51/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9988\n","Epoch 51: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 4.5715 - val_accuracy: 0.6258 - lr: 0.0010\n","Epoch 52/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9988\n","Epoch 52: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 4.7628 - val_accuracy: 0.6342 - lr: 0.0010\n","Epoch 53/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9988\n","Epoch 53: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 4.3357 - val_accuracy: 0.6184 - lr: 0.0010\n","Epoch 54/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9960\n","Epoch 54: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0069 - accuracy: 0.9960 - val_loss: 4.6334 - val_accuracy: 0.6156 - lr: 0.0010\n","Epoch 55/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9976\n","Epoch 55: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 4.9845 - val_accuracy: 0.6435 - lr: 0.0010\n","Epoch 56/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9980\n","Epoch 56: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 4.7616 - val_accuracy: 0.6240 - lr: 0.0010\n","Epoch 57/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9976\n","Epoch 57: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 150s 2s/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 4.4865 - val_accuracy: 0.6119 - lr: 0.0010\n","Epoch 58/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n","Epoch 58: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 5.0584 - val_accuracy: 0.6230 - lr: 0.0010\n","Epoch 59/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9992\n","Epoch 59: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 5.2386 - val_accuracy: 0.6240 - lr: 0.0010\n","Epoch 60/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 60: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 5.4658 - val_accuracy: 0.6240 - lr: 0.0010\n","Epoch 61/100\n","79/79 [==============================] - ETA: 0s - loss: 9.2016e-04 - accuracy: 0.9996\n","Epoch 61: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 9.2016e-04 - accuracy: 0.9996 - val_loss: 5.6304 - val_accuracy: 0.6342 - lr: 0.0010\n","Epoch 62/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9988\n","Epoch 62: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 5.5166 - val_accuracy: 0.6230 - lr: 0.0010\n","Epoch 63/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n","Epoch 63: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 5.2862 - val_accuracy: 0.6230 - lr: 0.0010\n","Epoch 64/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9996\n","Epoch 64: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 5.2009 - val_accuracy: 0.6202 - lr: 0.0010\n","Epoch 65/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9976\n","Epoch 65: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 147s 2s/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 4.4759 - val_accuracy: 0.6184 - lr: 0.0010\n","Epoch 66/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9789\n","Epoch 66: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 146s 2s/step - loss: 0.0900 - accuracy: 0.9789 - val_loss: 2.9853 - val_accuracy: 0.6082 - lr: 0.0010\n","Epoch 67/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9920\n","Epoch 67: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 3.0884 - val_accuracy: 0.6202 - lr: 0.0010\n","Epoch 68/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9988\n","Epoch 68: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 3.9116 - val_accuracy: 0.6230 - lr: 0.0010\n","Epoch 69/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9984\n","Epoch 69: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 145s 2s/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 3.9679 - val_accuracy: 0.6184 - lr: 0.0010\n","Epoch 70/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9980\n","Epoch 70: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 4.2156 - val_accuracy: 0.6128 - lr: 0.0010\n","Epoch 71/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9928\n","Epoch 71: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 4.1842 - val_accuracy: 0.6072 - lr: 0.0010\n","Epoch 72/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9972\n","Epoch 72: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0062 - accuracy: 0.9972 - val_loss: 4.1769 - val_accuracy: 0.6119 - lr: 0.0010\n","Epoch 73/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9976\n","Epoch 73: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0158 - accuracy: 0.9976 - val_loss: 4.6124 - val_accuracy: 0.6156 - lr: 0.0010\n","Epoch 74/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9972\n","Epoch 74: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 145s 2s/step - loss: 0.0632 - accuracy: 0.9972 - val_loss: 3.2644 - val_accuracy: 0.6249 - lr: 0.0010\n","Epoch 75/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9988\n","Epoch 75: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 146s 2s/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 3.4847 - val_accuracy: 0.6240 - lr: 0.0010\n","Epoch 76/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 76: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 3.7626 - val_accuracy: 0.6267 - lr: 0.0010\n","Epoch 77/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9988\n","Epoch 77: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 146s 2s/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 3.7666 - val_accuracy: 0.6314 - lr: 0.0010\n","Epoch 78/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9992\n","Epoch 78: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 3.9379 - val_accuracy: 0.6249 - lr: 0.0010\n","Epoch 79/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9992\n","Epoch 79: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 3.9548 - val_accuracy: 0.6230 - lr: 0.0010\n","Epoch 80/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9992\n","Epoch 80: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 4.0260 - val_accuracy: 0.6277 - lr: 0.0010\n","Epoch 81/100\n","79/79 [==============================] - ETA: 0s - loss: 9.7877e-04 - accuracy: 0.9996\n","Epoch 81: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 9.7877e-04 - accuracy: 0.9996 - val_loss: 3.9690 - val_accuracy: 0.6332 - lr: 0.0010\n","Epoch 82/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9996\n","Epoch 82: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 148s 2s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 4.0607 - val_accuracy: 0.6110 - lr: 0.0010\n","Epoch 83/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 83: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.1857 - val_accuracy: 0.6184 - lr: 0.0010\n","Epoch 84/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n","Epoch 84: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.1596 - val_accuracy: 0.6184 - lr: 0.0010\n","Epoch 85/100\n","79/79 [==============================] - ETA: 0s - loss: 7.1824e-04 - accuracy: 0.9996\n","Epoch 85: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 7.1824e-04 - accuracy: 0.9996 - val_loss: 4.3017 - val_accuracy: 0.6193 - lr: 0.0010\n","Epoch 86/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9996\n","Epoch 86: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 4.2716 - val_accuracy: 0.6175 - lr: 0.0010\n","Epoch 87/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996\n","Epoch 87: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 4.1946 - val_accuracy: 0.6221 - lr: 0.0010\n","Epoch 88/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9992\n","Epoch 88: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 4.1298 - val_accuracy: 0.6193 - lr: 0.0010\n","Epoch 89/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9992\n","Epoch 89: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 4.1953 - val_accuracy: 0.6249 - lr: 0.0010\n","Epoch 90/100\n","79/79 [==============================] - ETA: 0s - loss: 8.5296e-04 - accuracy: 0.9996\n","Epoch 90: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 8.5296e-04 - accuracy: 0.9996 - val_loss: 4.3034 - val_accuracy: 0.6193 - lr: 0.0010\n","Epoch 91/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 91: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 4.1553 - val_accuracy: 0.6267 - lr: 0.0010\n","Epoch 92/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 92: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 4.2089 - val_accuracy: 0.6212 - lr: 0.0010\n","Epoch 93/100\n","79/79 [==============================] - ETA: 0s - loss: 6.7512e-04 - accuracy: 1.0000\n","Epoch 93: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 6.7512e-04 - accuracy: 1.0000 - val_loss: 4.2964 - val_accuracy: 0.6221 - lr: 0.0010\n","Epoch 94/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9948\n","Epoch 94: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 143s 2s/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 4.6109 - val_accuracy: 0.6240 - lr: 0.0010\n","Epoch 95/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9956\n","Epoch 95: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 4.5323 - val_accuracy: 0.6286 - lr: 0.0010\n","Epoch 96/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9960\n","Epoch 96: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 4.3809 - val_accuracy: 0.6165 - lr: 0.0010\n","Epoch 97/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9988\n","Epoch 97: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 3.8424 - val_accuracy: 0.6305 - lr: 0.0010\n","Epoch 98/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 98: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 4.1753 - val_accuracy: 0.6258 - lr: 0.0010\n","Epoch 99/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9992\n","Epoch 99: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 144s 2s/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 3.9050 - val_accuracy: 0.6240 - lr: 0.0010\n","Epoch 100/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9992\n","Epoch 100: val_accuracy did not improve from 0.64345\n","79/79 [==============================] - 143s 2s/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 3.8199 - val_accuracy: 0.6258 - lr: 0.0010\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f73a05cd850>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["checkpointer = callbacks.ModelCheckpoint(filepath=resultPath+\"/checkpoint-{epoch:04d}.hdf5\", verbose=1, save_best_only=True, monitor='val_accuracy',mode='max')\n","csv_logger = CSVLogger(resultPath+'/result_logger.csv',separator=',', append=False)\n","reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=2, min_lr=0.001)\n","model2.fit(x_train,y_train,epochs=NO_OF_EPOCHS,verbose=1,batch_size=BATCH_SIZE,validation_data=(x_test,y_test),callbacks=[checkpointer,csv_logger,reduce_lr])"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"n_tUryRLktlV","executionInfo":{"status":"ok","timestamp":1656787255840,"user_tz":-330,"elapsed":1986,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}}},"outputs":[],"source":["model2.load_weights(resultPath + \"/checkpoint-0014.hdf5\")"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21395,"status":"ok","timestamp":1656787277221,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"tQWn8Zr3nzXI","outputId":"288df659-f3ea-4c1b-a2b0-8db60fc18c47"},"outputs":[{"output_type":"stream","name":"stdout","text":["34/34 [==============================] - 16s 439ms/step\n"]}],"source":["prediction_prob1 = model2.predict(x_test,verbose=1)\n","y_pred=np.round(prediction_prob1)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"2r-WEJNSqArc","executionInfo":{"status":"ok","timestamp":1656787251745,"user_tz":-330,"elapsed":540,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}}},"outputs":[],"source":["m1model = Model(inputs=model2.input,outputs=model2.get_layer('dense_1').output)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56014,"status":"ok","timestamp":1656787333223,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"yzEe8IqsqBdU","outputId":"aadd02e0-1f83-4590-967c-968d430c9e7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["79/79 [==============================] - 41s 518ms/step\n","34/34 [==============================] - 14s 424ms/step\n"]}],"source":["m1_x_train = m1model.predict(x_train,verbose=1)\n","m1_x_test = m1model.predict(x_test,verbose=1)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1656787333224,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"nSB3iXiAq4Uc","outputId":"62bb2c8c-700f-45f6-a76f-bb5d3c05dab5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of model1 Train and Test DF :  (2511, 1)  :  (1077, 1)\n"]}],"source":["print(\"Shape of model1 Train and Test DF : \",m1_x_train.shape,\" : \",m1_x_test.shape)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"_wiyuV9aq1pq","executionInfo":{"status":"ok","timestamp":1656787333224,"user_tz":-330,"elapsed":20,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}}},"outputs":[],"source":["def printMetrics(true,pred):\n","    print(\"Accuracy : \",accuracy_score(true, pred))\n","    print(\"Precision\",precision_score(true, pred , average=\"weighted\"))\n","    print(\"Recall : \",recall_score(true, pred , average=\"weighted\"))\n","    print(\"F1-score : \",f1_score(true, pred, average=\"weighted\"))\n","    print(\"Confusion Matrix : \")\n","    print(confusion_matrix(true, pred))\n","    print(classification_report(true,pred))"]},{"cell_type":"code","source":[""],"metadata":{"id":"xxh8VyRNR5Cp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["RSVM = svm.SVC(kernel='rbf',probability=True)\n","RSVM.fit(m1_x_train, y_train)\n","RSVMprob = RSVM.predict_proba(m1_x_test)\n","y_pred = RSVM.predict(m1_x_test)\n","printMetrics(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ldPnuEcR-HA","executionInfo":{"status":"ok","timestamp":1656787333952,"user_tz":-330,"elapsed":747,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}},"outputId":"382cccc9-a368-479f-98ff-e82f69971815"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy :  0.6555246053853296\n","Precision 0.6559783259632568\n","Recall :  0.6555246053853296\n","F1-score :  0.6556560013743798\n","Confusion Matrix : \n","[[336 179]\n"," [192 370]]\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.65      0.64       515\n","           1       0.67      0.66      0.67       562\n","\n","    accuracy                           0.66      1077\n","   macro avg       0.66      0.66      0.66      1077\n","weighted avg       0.66      0.66      0.66      1077\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"_h1NobD_s6WC"},"source":["**For gender classification**\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230981,"status":"ok","timestamp":1656737793619,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"vLYY2O5hs9Yu","outputId":"60e2508e-708e-4fd4-8c01-d84d69d39acb"},"outputs":[{"output_type":"stream","name":"stdout","text":[">>>Reading  female\n","1\n",">>>Reading  male\n","0\n"]}],"source":["DATA_PATH = '/content/drive/MyDrive/updatedDataset/Gender/'\n","genderData=[]\n","glabel=[]\n","ghashList=[]\n","count=2\n","for folder in os.listdir(DATA_PATH):\n","    print(\">>>Reading \",folder)\n","    count-=1\n","    print(count)\n","    \n","    for file in os.listdir(DATA_PATH+folder):\n","         if(str(file).endswith('.jpg') or str(file).endswith('.JPG') or str(file).endswith('.jpeg') or str(file).endswith('.JPEG')):\n","            img = image.imread(DATA_PATH+folder+'/'+file)\n","            hsh = hash(tuple(np.array(img).flatten()))\n","            if(hsh not in ghashList):\n","              genderData.append(resize(img, (156, 156, 3)))\n","              ghashList.append(hsh)\n","              glabel.append(count)\n","genderData=np.array(genderData)\n","glabel=np.array(glabel)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"HeRR4011ucY1","executionInfo":{"status":"ok","timestamp":1656738071812,"user_tz":-330,"elapsed":562,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}}},"outputs":[],"source":["resultPath = '/content/drive/MyDrive/gResult'\n","train_folder = os.listdir(DATA_PATH)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1656738072322,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"x05sctmqvEpE","outputId":"11b5df3e-8464-4d72-80cd-9d88047fe018"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of maleGarments 1779\n","Number of femaleGarments 1843\n"]}],"source":["print(\"Number of maleGarments\",len(glabel[glabel==0]))\n","print(\"Number of femaleGarments\",len(glabel[glabel==1]))"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656738073724,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"nI9T_XNNwpbN","outputId":"9d29fe48-3ce9-48e7-f2d2-db47722b4460"},"outputs":[{"output_type":"stream","name":"stdout","text":["Gender data shape :  (3622, 156, 156, 3)  Label shape :  (3622,)\n"]}],"source":["print(\"Gender data shape : \",genderData.shape,\" Label shape : \",glabel.shape)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"9Pc1sq2HwOWH","executionInfo":{"status":"ok","timestamp":1656738077582,"user_tz":-330,"elapsed":1675,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}}},"outputs":[],"source":["testPercentage=0.3\n","x_train,x_test,y_train,y_test = train_test_split(genderData,glabel,test_size = testPercentage,random_state=50, stratify=glabel,shuffle=True)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656738077583,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"HWuQLRh3wU7A","outputId":"e132360e-0057-4da9-d863-3d1099ec1b6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape :  (2535, 156, 156, 3)  y_train shape :  (2535,)\n","x_test shape :  (1087, 156, 156, 3)  y_test shape :  (1087,)\n"]}],"source":["print(\"x_train shape : \",x_train.shape,\" y_train shape : \",y_train.shape)\n","print(\"x_test shape : \",x_test.shape,\" y_test shape : \",y_test.shape)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1656738079050,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"OMixBXelwgvR","outputId":"244a8e95-465e-47cf-aa2b-9baed3456898"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of train male male 1245\n","Number of train female garments 1290\n","Number of test male garments  534\n","Number of test female garments 553\n"]}],"source":["print(\"Number of train male male\",len(y_train[y_train==0]))\n","print(\"Number of train female garments\",len(y_train[y_train==1]))\n","\n","print(\"Number of test male garments \",len(y_test[y_test==0]))\n","print(\"Number of test female garments\",len(y_test[y_test==1]))"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10583621,"status":"ok","timestamp":1656748667966,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"NZJxHFmtxPMF","outputId":"8d3f1efc-1adf-4fcb-e2a5-a8562646f2d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","80/80 [==============================] - ETA: 0s - loss: 0.9923 - accuracy: 0.5093\n","Epoch 1: val_accuracy improved from -inf to 0.60626, saving model to /content/drive/MyDrive/gResult/checkpoint-0001.hdf5\n","80/80 [==============================] - 113s 1s/step - loss: 0.9923 - accuracy: 0.5093 - val_loss: 0.6850 - val_accuracy: 0.6063 - lr: 0.0010\n","Epoch 2/100\n","80/80 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.6114\n","Epoch 2: val_accuracy did not improve from 0.60626\n","80/80 [==============================] - 108s 1s/step - loss: 0.6579 - accuracy: 0.6114 - val_loss: 0.6576 - val_accuracy: 0.6035 - lr: 0.0010\n","Epoch 3/100\n","80/80 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.7101\n","Epoch 3: val_accuracy improved from 0.60626 to 0.65501, saving model to /content/drive/MyDrive/gResult/checkpoint-0003.hdf5\n","80/80 [==============================] - 111s 1s/step - loss: 0.5527 - accuracy: 0.7101 - val_loss: 0.6676 - val_accuracy: 0.6550 - lr: 0.0010\n","Epoch 4/100\n","80/80 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.8146\n","Epoch 4: val_accuracy did not improve from 0.65501\n","80/80 [==============================] - 107s 1s/step - loss: 0.4008 - accuracy: 0.8146 - val_loss: 0.7476 - val_accuracy: 0.6550 - lr: 0.0010\n","Epoch 5/100\n","80/80 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.8986\n","Epoch 5: val_accuracy did not improve from 0.65501\n","80/80 [==============================] - 105s 1s/step - loss: 0.2335 - accuracy: 0.8986 - val_loss: 1.0977 - val_accuracy: 0.6550 - lr: 0.0010\n","Epoch 6/100\n","80/80 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9404\n","Epoch 6: val_accuracy improved from 0.65501 to 0.65593, saving model to /content/drive/MyDrive/gResult/checkpoint-0006.hdf5\n","80/80 [==============================] - 109s 1s/step - loss: 0.1501 - accuracy: 0.9404 - val_loss: 1.3719 - val_accuracy: 0.6559 - lr: 0.0010\n","Epoch 7/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9665\n","Epoch 7: val_accuracy improved from 0.65593 to 0.65777, saving model to /content/drive/MyDrive/gResult/checkpoint-0007.hdf5\n","80/80 [==============================] - 110s 1s/step - loss: 0.0910 - accuracy: 0.9665 - val_loss: 1.7982 - val_accuracy: 0.6578 - lr: 0.0010\n","Epoch 8/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9751\n","Epoch 8: val_accuracy did not improve from 0.65777\n","80/80 [==============================] - 108s 1s/step - loss: 0.0588 - accuracy: 0.9751 - val_loss: 1.9814 - val_accuracy: 0.6523 - lr: 0.0010\n","Epoch 9/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9811\n","Epoch 9: val_accuracy did not improve from 0.65777\n","80/80 [==============================] - 107s 1s/step - loss: 0.0443 - accuracy: 0.9811 - val_loss: 2.1131 - val_accuracy: 0.6559 - lr: 0.0010\n","Epoch 10/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9862\n","Epoch 10: val_accuracy improved from 0.65777 to 0.66605, saving model to /content/drive/MyDrive/gResult/checkpoint-0010.hdf5\n","80/80 [==============================] - 109s 1s/step - loss: 0.0380 - accuracy: 0.9862 - val_loss: 2.0706 - val_accuracy: 0.6661 - lr: 0.0010\n","Epoch 11/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9799\n","Epoch 11: val_accuracy improved from 0.66605 to 0.67433, saving model to /content/drive/MyDrive/gResult/checkpoint-0011.hdf5\n","80/80 [==============================] - 108s 1s/step - loss: 0.0787 - accuracy: 0.9799 - val_loss: 2.1665 - val_accuracy: 0.6743 - lr: 0.0010\n","Epoch 12/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9874\n","Epoch 12: val_accuracy did not improve from 0.67433\n","80/80 [==============================] - 108s 1s/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 2.4706 - val_accuracy: 0.6725 - lr: 0.0010\n","Epoch 13/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9929\n","Epoch 13: val_accuracy improved from 0.67433 to 0.68629, saving model to /content/drive/MyDrive/gResult/checkpoint-0013.hdf5\n","80/80 [==============================] - 113s 1s/step - loss: 0.0194 - accuracy: 0.9929 - val_loss: 2.5245 - val_accuracy: 0.6863 - lr: 0.0010\n","Epoch 14/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9862\n","Epoch 14: val_accuracy did not improve from 0.68629\n","80/80 [==============================] - 109s 1s/step - loss: 0.0399 - accuracy: 0.9862 - val_loss: 2.4349 - val_accuracy: 0.6771 - lr: 0.0010\n","Epoch 15/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9921\n","Epoch 15: val_accuracy did not improve from 0.68629\n","80/80 [==============================] - 107s 1s/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 2.7633 - val_accuracy: 0.6845 - lr: 0.0010\n","Epoch 16/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9913\n","Epoch 16: val_accuracy did not improve from 0.68629\n","80/80 [==============================] - 106s 1s/step - loss: 0.0214 - accuracy: 0.9913 - val_loss: 2.5032 - val_accuracy: 0.6550 - lr: 0.0010\n","Epoch 17/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9937\n","Epoch 17: val_accuracy did not improve from 0.68629\n","80/80 [==============================] - 106s 1s/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 2.6502 - val_accuracy: 0.6799 - lr: 0.0010\n","Epoch 18/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9953\n","Epoch 18: val_accuracy did not improve from 0.68629\n","80/80 [==============================] - 104s 1s/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 2.8987 - val_accuracy: 0.6762 - lr: 0.0010\n","Epoch 19/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9972\n","Epoch 19: val_accuracy did not improve from 0.68629\n","80/80 [==============================] - 106s 1s/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 3.0459 - val_accuracy: 0.6651 - lr: 0.0010\n","Epoch 20/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9957\n","Epoch 20: val_accuracy did not improve from 0.68629\n","80/80 [==============================] - 104s 1s/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 2.6597 - val_accuracy: 0.6799 - lr: 0.0010\n","Epoch 21/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9949\n","Epoch 21: val_accuracy improved from 0.68629 to 0.68813, saving model to /content/drive/MyDrive/gResult/checkpoint-0021.hdf5\n","80/80 [==============================] - 106s 1s/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 3.0372 - val_accuracy: 0.6881 - lr: 0.0010\n","Epoch 22/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9929\n","Epoch 22: val_accuracy did not improve from 0.68813\n","80/80 [==============================] - 106s 1s/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 3.0773 - val_accuracy: 0.6826 - lr: 0.0010\n","Epoch 23/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9945\n","Epoch 23: val_accuracy did not improve from 0.68813\n","80/80 [==============================] - 104s 1s/step - loss: 0.0407 - accuracy: 0.9945 - val_loss: 2.7378 - val_accuracy: 0.6789 - lr: 0.0010\n","Epoch 24/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9866\n","Epoch 24: val_accuracy did not improve from 0.68813\n","80/80 [==============================] - 105s 1s/step - loss: 0.0491 - accuracy: 0.9866 - val_loss: 2.4978 - val_accuracy: 0.6716 - lr: 0.0010\n","Epoch 25/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9941\n","Epoch 25: val_accuracy did not improve from 0.68813\n","80/80 [==============================] - 104s 1s/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 2.4254 - val_accuracy: 0.6716 - lr: 0.0010\n","Epoch 26/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9953\n","Epoch 26: val_accuracy improved from 0.68813 to 0.68905, saving model to /content/drive/MyDrive/gResult/checkpoint-0026.hdf5\n","80/80 [==============================] - 105s 1s/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 2.9319 - val_accuracy: 0.6891 - lr: 0.0010\n","Epoch 27/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9976\n","Epoch 27: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 107s 1s/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 2.9437 - val_accuracy: 0.6817 - lr: 0.0010\n","Epoch 28/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9972\n","Epoch 28: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 3.1570 - val_accuracy: 0.6808 - lr: 0.0010\n","Epoch 29/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9980\n","Epoch 29: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 2.7394 - val_accuracy: 0.6854 - lr: 0.0010\n","Epoch 30/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9976\n","Epoch 30: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 2.8735 - val_accuracy: 0.6863 - lr: 0.0010\n","Epoch 31/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9957\n","Epoch 31: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 2.8799 - val_accuracy: 0.6835 - lr: 0.0010\n","Epoch 32/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9933\n","Epoch 32: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 2.6472 - val_accuracy: 0.6670 - lr: 0.0010\n","Epoch 33/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n","Epoch 33: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 3.2115 - val_accuracy: 0.6697 - lr: 0.0010\n","Epoch 34/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9980\n","Epoch 34: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 3.4834 - val_accuracy: 0.6734 - lr: 0.0010\n","Epoch 35/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9972\n","Epoch 35: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 4.0019 - val_accuracy: 0.6679 - lr: 0.0010\n","Epoch 36/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n","Epoch 36: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 3.3846 - val_accuracy: 0.6661 - lr: 0.0010\n","Epoch 37/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9976\n","Epoch 37: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 3.2800 - val_accuracy: 0.6743 - lr: 0.0010\n","Epoch 38/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9964\n","Epoch 38: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 3.4864 - val_accuracy: 0.6771 - lr: 0.0010\n","Epoch 39/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9949\n","Epoch 39: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 3.0943 - val_accuracy: 0.6550 - lr: 0.0010\n","Epoch 40/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9964\n","Epoch 40: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 3.4104 - val_accuracy: 0.6596 - lr: 0.0010\n","Epoch 41/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9972\n","Epoch 41: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 3.4720 - val_accuracy: 0.6707 - lr: 0.0010\n","Epoch 42/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9976\n","Epoch 42: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 3.2592 - val_accuracy: 0.6578 - lr: 0.0010\n","Epoch 43/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9957\n","Epoch 43: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 3.0696 - val_accuracy: 0.6661 - lr: 0.0010\n","Epoch 44/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9949\n","Epoch 44: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 3.3089 - val_accuracy: 0.6615 - lr: 0.0010\n","Epoch 45/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9964\n","Epoch 45: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 3.4483 - val_accuracy: 0.6670 - lr: 0.0010\n","Epoch 46/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9988\n","Epoch 46: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 3.5548 - val_accuracy: 0.6707 - lr: 0.0010\n","Epoch 47/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9953\n","Epoch 47: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 3.8138 - val_accuracy: 0.6771 - lr: 0.0010\n","Epoch 48/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9953\n","Epoch 48: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0090 - accuracy: 0.9953 - val_loss: 4.1538 - val_accuracy: 0.6743 - lr: 0.0010\n","Epoch 49/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9961\n","Epoch 49: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 4.1258 - val_accuracy: 0.6725 - lr: 0.0010\n","Epoch 50/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9972\n","Epoch 50: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0163 - accuracy: 0.9972 - val_loss: 4.1795 - val_accuracy: 0.6670 - lr: 0.0010\n","Epoch 51/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n","Epoch 51: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 4.1029 - val_accuracy: 0.6697 - lr: 0.0010\n","Epoch 52/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9984\n","Epoch 52: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 107s 1s/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 4.1639 - val_accuracy: 0.6688 - lr: 0.0010\n","Epoch 53/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9980\n","Epoch 53: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 4.0421 - val_accuracy: 0.6605 - lr: 0.0010\n","Epoch 54/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9988\n","Epoch 54: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 3.9897 - val_accuracy: 0.6633 - lr: 0.0010\n","Epoch 55/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9992\n","Epoch 55: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 3.8085 - val_accuracy: 0.6615 - lr: 0.0010\n","Epoch 56/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9980\n","Epoch 56: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 4.6163 - val_accuracy: 0.6495 - lr: 0.0010\n","Epoch 57/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n","Epoch 57: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 4.0804 - val_accuracy: 0.6661 - lr: 0.0010\n","Epoch 58/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9980\n","Epoch 58: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 3.9306 - val_accuracy: 0.6633 - lr: 0.0010\n","Epoch 59/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9972\n","Epoch 59: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0051 - accuracy: 0.9972 - val_loss: 4.3875 - val_accuracy: 0.6403 - lr: 0.0010\n","Epoch 60/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9945\n","Epoch 60: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0123 - accuracy: 0.9945 - val_loss: 4.0989 - val_accuracy: 0.6504 - lr: 0.0010\n","Epoch 61/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9980\n","Epoch 61: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 4.4828 - val_accuracy: 0.6532 - lr: 0.0010\n","Epoch 62/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9976\n","Epoch 62: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 4.5983 - val_accuracy: 0.6633 - lr: 0.0010\n","Epoch 63/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9972\n","Epoch 63: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0062 - accuracy: 0.9972 - val_loss: 3.9517 - val_accuracy: 0.6486 - lr: 0.0010\n","Epoch 64/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9964\n","Epoch 64: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 4.5059 - val_accuracy: 0.6642 - lr: 0.0010\n","Epoch 65/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9976\n","Epoch 65: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 4.2538 - val_accuracy: 0.6679 - lr: 0.0010\n","Epoch 66/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9988\n","Epoch 66: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 4.5741 - val_accuracy: 0.6753 - lr: 0.0010\n","Epoch 67/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9953\n","Epoch 67: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 4.1821 - val_accuracy: 0.6605 - lr: 0.0010\n","Epoch 68/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9980\n","Epoch 68: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0039 - accuracy: 0.9980 - val_loss: 4.7727 - val_accuracy: 0.6615 - lr: 0.0010\n","Epoch 69/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9992\n","Epoch 69: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 4.7888 - val_accuracy: 0.6651 - lr: 0.0010\n","Epoch 70/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9988\n","Epoch 70: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 5.0177 - val_accuracy: 0.6670 - lr: 0.0010\n","Epoch 71/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996\n","Epoch 71: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 5.0177 - val_accuracy: 0.6615 - lr: 0.0010\n","Epoch 72/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9976\n","Epoch 72: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 4.5086 - val_accuracy: 0.6605 - lr: 0.0010\n","Epoch 73/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9905\n","Epoch 73: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 103s 1s/step - loss: 0.0436 - accuracy: 0.9905 - val_loss: 4.1771 - val_accuracy: 0.6532 - lr: 0.0010\n","Epoch 74/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9961\n","Epoch 74: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 4.6071 - val_accuracy: 0.6624 - lr: 0.0010\n","Epoch 75/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n","Epoch 75: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 4.6519 - val_accuracy: 0.6734 - lr: 0.0010\n","Epoch 76/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n","Epoch 76: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 4.6825 - val_accuracy: 0.6743 - lr: 0.0010\n","Epoch 77/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9992\n","Epoch 77: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 4.8825 - val_accuracy: 0.6753 - lr: 0.0010\n","Epoch 78/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9988\n","Epoch 78: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 4.9503 - val_accuracy: 0.6808 - lr: 0.0010\n","Epoch 79/100\n","80/80 [==============================] - ETA: 0s - loss: 8.1768e-04 - accuracy: 0.9996\n","Epoch 79: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 103s 1s/step - loss: 8.1768e-04 - accuracy: 0.9996 - val_loss: 4.9898 - val_accuracy: 0.6799 - lr: 0.0010\n","Epoch 80/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n","Epoch 80: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 5.0248 - val_accuracy: 0.6789 - lr: 0.0010\n","Epoch 81/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9988\n","Epoch 81: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 4.9172 - val_accuracy: 0.6725 - lr: 0.0010\n","Epoch 82/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9980\n","Epoch 82: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 4.1443 - val_accuracy: 0.6615 - lr: 0.0010\n","Epoch 83/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9992\n","Epoch 83: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 4.2497 - val_accuracy: 0.6707 - lr: 0.0010\n","Epoch 84/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9992\n","Epoch 84: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 103s 1s/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 4.4397 - val_accuracy: 0.6624 - lr: 0.0010\n","Epoch 85/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9992\n","Epoch 85: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 103s 1s/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 4.4514 - val_accuracy: 0.6707 - lr: 0.0010\n","Epoch 86/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9988\n","Epoch 86: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 4.4507 - val_accuracy: 0.6651 - lr: 0.0010\n","Epoch 87/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n","Epoch 87: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 104s 1s/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 4.5533 - val_accuracy: 0.6725 - lr: 0.0010\n","Epoch 88/100\n","80/80 [==============================] - ETA: 0s - loss: 8.8321e-04 - accuracy: 0.9996\n","Epoch 88: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 8.8321e-04 - accuracy: 0.9996 - val_loss: 4.5359 - val_accuracy: 0.6734 - lr: 0.0010\n","Epoch 89/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9992\n","Epoch 89: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 4.5061 - val_accuracy: 0.6753 - lr: 0.0010\n","Epoch 90/100\n","80/80 [==============================] - ETA: 0s - loss: 9.0021e-04 - accuracy: 0.9996\n","Epoch 90: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 9.0021e-04 - accuracy: 0.9996 - val_loss: 4.5083 - val_accuracy: 0.6771 - lr: 0.0010\n","Epoch 91/100\n","80/80 [==============================] - ETA: 0s - loss: 9.4929e-04 - accuracy: 0.9992\n","Epoch 91: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 107s 1s/step - loss: 9.4929e-04 - accuracy: 0.9992 - val_loss: 4.5386 - val_accuracy: 0.6762 - lr: 0.0010\n","Epoch 92/100\n","80/80 [==============================] - ETA: 0s - loss: 7.9316e-04 - accuracy: 0.9996\n","Epoch 92: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 7.9316e-04 - accuracy: 0.9996 - val_loss: 4.5491 - val_accuracy: 0.6762 - lr: 0.0010\n","Epoch 93/100\n","80/80 [==============================] - ETA: 0s - loss: 6.1892e-04 - accuracy: 0.9996\n","Epoch 93: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 6.1892e-04 - accuracy: 0.9996 - val_loss: 4.5599 - val_accuracy: 0.6771 - lr: 0.0010\n","Epoch 94/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n","Epoch 94: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.4975 - val_accuracy: 0.6743 - lr: 0.0010\n","Epoch 95/100\n","80/80 [==============================] - ETA: 0s - loss: 7.6917e-04 - accuracy: 0.9996\n","Epoch 95: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 7.6917e-04 - accuracy: 0.9996 - val_loss: 4.7398 - val_accuracy: 0.6716 - lr: 0.0010\n","Epoch 96/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9992\n","Epoch 96: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 4.9786 - val_accuracy: 0.6799 - lr: 0.0010\n","Epoch 97/100\n","80/80 [==============================] - ETA: 0s - loss: 9.5684e-04 - accuracy: 0.9992\n","Epoch 97: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 9.5684e-04 - accuracy: 0.9992 - val_loss: 4.8657 - val_accuracy: 0.6799 - lr: 0.0010\n","Epoch 98/100\n","80/80 [==============================] - ETA: 0s - loss: 7.3680e-04 - accuracy: 0.9996\n","Epoch 98: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 7.3680e-04 - accuracy: 0.9996 - val_loss: 4.8391 - val_accuracy: 0.6771 - lr: 0.0010\n","Epoch 99/100\n","80/80 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n","Epoch 99: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 105s 1s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.8158 - val_accuracy: 0.6817 - lr: 0.0010\n","Epoch 100/100\n","80/80 [==============================] - ETA: 0s - loss: 8.5412e-04 - accuracy: 0.9992\n","Epoch 100: val_accuracy did not improve from 0.68905\n","80/80 [==============================] - 106s 1s/step - loss: 8.5412e-04 - accuracy: 0.9992 - val_loss: 4.7222 - val_accuracy: 0.6753 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0ed1276290>"]},"metadata":{},"execution_count":26}],"source":["checkpointer = callbacks.ModelCheckpoint(filepath=resultPath+\"/checkpoint-{epoch:04d}.hdf5\", verbose=1, save_best_only=True, monitor='val_accuracy',mode='max')\n","csv_logger = CSVLogger(resultPath+'/result_logger.csv',separator=',', append=False)\n","reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=2, min_lr=0.001)\n","model2.fit(x_train,y_train,epochs=NO_OF_EPOCHS,verbose=1,batch_size=BATCH_SIZE,validation_data=(x_test,y_test),callbacks=[checkpointer,csv_logger,reduce_lr])"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"CDnm3pcOxaoT","executionInfo":{"status":"ok","timestamp":1656748731856,"user_tz":-330,"elapsed":3655,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}}},"outputs":[],"source":["model2.load_weights(resultPath + \"/checkpoint-0043.hdf5\")"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12432,"status":"ok","timestamp":1656748745973,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"},"user_tz":-330},"id":"RDRW4ArSx0yF","outputId":"c0c22ee1-1b09-4d45-b404-6e71d729f715"},"outputs":[{"output_type":"stream","name":"stdout","text":["34/34 [==============================] - 11s 333ms/step\n"]}],"source":["prediction_prob1 = model2.predict(x_test,verbose=1)\n","y_pred=np.round(prediction_prob1)"]},{"cell_type":"code","source":["m1model = Model(inputs=model2.input,outputs=model2.get_layer('dense_1').output)"],"metadata":{"id":"Pma_17qW7EBn","executionInfo":{"status":"ok","timestamp":1656748872485,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["m1_x_train = m1model.predict(x_train,verbose=1)\n","m1_x_test = m1model.predict(x_test,verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zk_vgdvN7ErO","executionInfo":{"status":"ok","timestamp":1656748917801,"user_tz":-330,"elapsed":43069,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}},"outputId":"b0a697f0-59c6-4a1c-be02-0ea13250e159"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["80/80 [==============================] - 29s 361ms/step\n","34/34 [==============================] - 13s 364ms/step\n"]}]},{"cell_type":"code","source":["print(\"Shape of model1 Train and Test DF : \",m1_x_train.shape,\" : \",m1_x_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMDZxk957bGL","executionInfo":{"status":"ok","timestamp":1656748920597,"user_tz":-330,"elapsed":564,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}},"outputId":"f5fd1579-91bf-47e6-e0ee-529e01ba74db"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of model1 Train and Test DF :  (2535, 1)  :  (1087, 1)\n"]}]},{"cell_type":"code","source":["def printMetrics(true,pred):\n","    print(\"Accuracy : \",accuracy_score(true, pred))\n","    print(\"Precision\",precision_score(true, pred , average=\"weighted\"))\n","    print(\"Recall : \",recall_score(true, pred , average=\"weighted\"))\n","    print(\"F1-score : \",f1_score(true, pred, average=\"weighted\"))\n","    print(\"Confusion Matrix : \")\n","    print(confusion_matrix(true, pred))\n","    print(classification_report(true,pred))"],"metadata":{"id":"RewZeKC97paP","executionInfo":{"status":"ok","timestamp":1656748942662,"user_tz":-330,"elapsed":538,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["RSVM = svm.SVC(kernel='rbf',probability=True)\n","RSVM.fit(m1_x_train, y_train)\n","RSVMprob = RSVM.predict_proba(m1_x_test)\n","y_pred = RSVM.predict(m1_x_test)\n","print(\"cost-insensitive\")\n","printMetrics(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XA9i2PfO7tnW","executionInfo":{"status":"ok","timestamp":1656748960965,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shubham Pandey","userId":"10007737772413720779"}},"outputId":"6430122e-0cfb-4684-adff-d23e5d8f1067"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["cost-insensitive\n","Accuracy :  0.7175712971481141\n","Precision 0.7176709718188835\n","Recall :  0.7175712971481141\n","F1-score :  0.7175913779920435\n","Confusion Matrix : \n","[[384 150]\n"," [157 396]]\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.72      0.71       534\n","           1       0.73      0.72      0.72       553\n","\n","    accuracy                           0.72      1087\n","   macro avg       0.72      0.72      0.72      1087\n","weighted avg       0.72      0.72      0.72      1087\n","\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"weastern/ethenic and gender classification.ipynb","provenance":[],"mount_file_id":"1lHs9P4SJfqPhYx52iilbQ9r8EtgxIyen","authorship_tag":"ABX9TyNmaF0hTyEeEzqVQ4GijqOB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}